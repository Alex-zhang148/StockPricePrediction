{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import collections\n",
    "from sklearn import preprocessing\n",
    "from matplotlib.pyplot import figure, show\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix\n",
    "import shutil\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, collections.Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.812500</td>\n",
       "      <td>4.156250</td>\n",
       "      <td>3.812500</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>3675600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.125000</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.015625</td>\n",
       "      <td>1077600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.031250</td>\n",
       "      <td>3.953125</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>437200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.843750</td>\n",
       "      <td>3.843750</td>\n",
       "      <td>1883600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.734375</td>\n",
       "      <td>3.734375</td>\n",
       "      <td>3.390625</td>\n",
       "      <td>3.390625</td>\n",
       "      <td>7931600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High       Low     Close   Volume\n",
       "0  3.812500  4.156250  3.812500  4.125000  3675600\n",
       "1  4.125000  4.125000  4.000000  4.015625  1077600\n",
       "2  4.000000  4.031250  3.953125  4.000000   437200\n",
       "3  4.000000  4.000000  3.843750  3.843750  1883600\n",
       "4  3.734375  3.734375  3.390625  3.390625  7931600"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess = True\n",
    "\n",
    "filename_read = os.path.join(\"CSC215_P2_Stock_Price.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?']) # No NA Values found\n",
    "df.drop(['Date','Adj_Close'],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.unique of 0        3675600\n",
       "1        1077600\n",
       "2         437200\n",
       "3        1883600\n",
       "4        7931600\n",
       "5       11486800\n",
       "6       13136800\n",
       "7        6349600\n",
       "8        7181200\n",
       "9       13904800\n",
       "10       5280800\n",
       "11       6590000\n",
       "12       8546400\n",
       "13       6874400\n",
       "14       2626000\n",
       "15       2992000\n",
       "16       2896000\n",
       "17       4662400\n",
       "18       4558800\n",
       "19       3815200\n",
       "20       4635600\n",
       "21       5321200\n",
       "22       4085200\n",
       "23       3539200\n",
       "24       4310000\n",
       "25       2684400\n",
       "26       4164400\n",
       "27       3610400\n",
       "28       1710800\n",
       "29       1435600\n",
       "          ...   \n",
       "4362     2185100\n",
       "4363     1467900\n",
       "4364     1297200\n",
       "4365     1249500\n",
       "4366     1469600\n",
       "4367      962800\n",
       "4368      723200\n",
       "4369      976900\n",
       "4370      980400\n",
       "4371      982100\n",
       "4372      673800\n",
       "4373     1294500\n",
       "4374      898400\n",
       "4375      943600\n",
       "4376      981500\n",
       "4377     1134600\n",
       "4378     1089000\n",
       "4379     1433200\n",
       "4380     2074000\n",
       "4381     1269400\n",
       "4382     1206400\n",
       "4383     1050200\n",
       "4384     1366000\n",
       "4385      929200\n",
       "4386     1091400\n",
       "4387      950000\n",
       "4388     1805200\n",
       "4389     2136700\n",
       "4390     1251600\n",
       "4391     1611700\n",
       "Name: Volume, Length: 4392, dtype: int64>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Volume'].unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.894209</td>\n",
       "      <td>-0.885022</td>\n",
       "      <td>-0.892306</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>1.104812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.883762</td>\n",
       "      <td>-0.886056</td>\n",
       "      <td>-0.885975</td>\n",
       "      <td>4.015625</td>\n",
       "      <td>-0.497301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.887941</td>\n",
       "      <td>-0.889159</td>\n",
       "      <td>-0.887558</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-0.892217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.887941</td>\n",
       "      <td>-0.890194</td>\n",
       "      <td>-0.891251</td>\n",
       "      <td>3.843750</td>\n",
       "      <td>-0.000263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.896820</td>\n",
       "      <td>-0.898986</td>\n",
       "      <td>-0.906551</td>\n",
       "      <td>3.390625</td>\n",
       "      <td>3.729366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.904655</td>\n",
       "      <td>-0.900020</td>\n",
       "      <td>-0.904969</td>\n",
       "      <td>3.437500</td>\n",
       "      <td>5.921757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.903610</td>\n",
       "      <td>-0.904158</td>\n",
       "      <td>-0.916576</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>6.939265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.905700</td>\n",
       "      <td>-0.904675</td>\n",
       "      <td>-0.904441</td>\n",
       "      <td>3.484375</td>\n",
       "      <td>2.753792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.904655</td>\n",
       "      <td>-0.903641</td>\n",
       "      <td>-0.903913</td>\n",
       "      <td>3.578125</td>\n",
       "      <td>3.266616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.901521</td>\n",
       "      <td>-0.896400</td>\n",
       "      <td>-0.899693</td>\n",
       "      <td>3.609375</td>\n",
       "      <td>7.412869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.898387</td>\n",
       "      <td>-0.898469</td>\n",
       "      <td>-0.898637</td>\n",
       "      <td>3.640625</td>\n",
       "      <td>2.094693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.902044</td>\n",
       "      <td>-0.901572</td>\n",
       "      <td>-0.900748</td>\n",
       "      <td>3.578125</td>\n",
       "      <td>2.902040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.903088</td>\n",
       "      <td>-0.902089</td>\n",
       "      <td>-0.901803</td>\n",
       "      <td>3.578125</td>\n",
       "      <td>4.108496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.902044</td>\n",
       "      <td>-0.901572</td>\n",
       "      <td>-0.900220</td>\n",
       "      <td>3.613275</td>\n",
       "      <td>3.077421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.900999</td>\n",
       "      <td>-0.902606</td>\n",
       "      <td>-0.901803</td>\n",
       "      <td>3.609375</td>\n",
       "      <td>0.457554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.902044</td>\n",
       "      <td>-0.903124</td>\n",
       "      <td>-0.902331</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>0.683255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.900999</td>\n",
       "      <td>-0.902606</td>\n",
       "      <td>-0.903386</td>\n",
       "      <td>3.515625</td>\n",
       "      <td>0.624055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.902566</td>\n",
       "      <td>-0.901572</td>\n",
       "      <td>-0.900748</td>\n",
       "      <td>3.593750</td>\n",
       "      <td>1.713344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.902044</td>\n",
       "      <td>-0.900538</td>\n",
       "      <td>-0.900748</td>\n",
       "      <td>3.656250</td>\n",
       "      <td>1.649456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.901521</td>\n",
       "      <td>-0.901572</td>\n",
       "      <td>-0.901803</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>1.190899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.902044</td>\n",
       "      <td>-0.897434</td>\n",
       "      <td>-0.903913</td>\n",
       "      <td>3.765625</td>\n",
       "      <td>1.696817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.895253</td>\n",
       "      <td>-0.886056</td>\n",
       "      <td>-0.894417</td>\n",
       "      <td>3.828125</td>\n",
       "      <td>2.119607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.895776</td>\n",
       "      <td>-0.897952</td>\n",
       "      <td>-0.898110</td>\n",
       "      <td>3.703125</td>\n",
       "      <td>1.357401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.898387</td>\n",
       "      <td>-0.898469</td>\n",
       "      <td>-0.898637</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>1.020698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.896298</td>\n",
       "      <td>-0.898469</td>\n",
       "      <td>-0.899165</td>\n",
       "      <td>3.687500</td>\n",
       "      <td>1.496028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.899432</td>\n",
       "      <td>-0.900538</td>\n",
       "      <td>-0.899165</td>\n",
       "      <td>3.640625</td>\n",
       "      <td>0.493567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.903088</td>\n",
       "      <td>-0.902089</td>\n",
       "      <td>-0.902331</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>1.406241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.901521</td>\n",
       "      <td>-0.900538</td>\n",
       "      <td>-0.900748</td>\n",
       "      <td>3.687500</td>\n",
       "      <td>1.064605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.897343</td>\n",
       "      <td>-0.895366</td>\n",
       "      <td>-0.895472</td>\n",
       "      <td>3.781250</td>\n",
       "      <td>-0.106824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.893164</td>\n",
       "      <td>-0.893297</td>\n",
       "      <td>-0.892834</td>\n",
       "      <td>3.812500</td>\n",
       "      <td>-0.276532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4362</th>\n",
       "      <td>2.854359</td>\n",
       "      <td>2.823358</td>\n",
       "      <td>2.806653</td>\n",
       "      <td>115.510002</td>\n",
       "      <td>0.185663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4363</th>\n",
       "      <td>2.848676</td>\n",
       "      <td>2.812765</td>\n",
       "      <td>2.830965</td>\n",
       "      <td>115.180000</td>\n",
       "      <td>-0.256614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4364</th>\n",
       "      <td>2.851685</td>\n",
       "      <td>2.824351</td>\n",
       "      <td>2.865743</td>\n",
       "      <td>115.269997</td>\n",
       "      <td>-0.361880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4365</th>\n",
       "      <td>2.831294</td>\n",
       "      <td>2.799856</td>\n",
       "      <td>2.790108</td>\n",
       "      <td>114.239998</td>\n",
       "      <td>-0.391295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4366</th>\n",
       "      <td>2.797531</td>\n",
       "      <td>2.843549</td>\n",
       "      <td>2.820159</td>\n",
       "      <td>116.449997</td>\n",
       "      <td>-0.255565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4367</th>\n",
       "      <td>2.883442</td>\n",
       "      <td>2.850169</td>\n",
       "      <td>2.878912</td>\n",
       "      <td>116.190002</td>\n",
       "      <td>-0.568095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4368</th>\n",
       "      <td>2.862716</td>\n",
       "      <td>2.841563</td>\n",
       "      <td>2.891743</td>\n",
       "      <td>116.480003</td>\n",
       "      <td>-0.715849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4369</th>\n",
       "      <td>2.872076</td>\n",
       "      <td>2.859768</td>\n",
       "      <td>2.889042</td>\n",
       "      <td>116.160004</td>\n",
       "      <td>-0.559400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4370</th>\n",
       "      <td>2.847673</td>\n",
       "      <td>2.833619</td>\n",
       "      <td>2.869795</td>\n",
       "      <td>116.260002</td>\n",
       "      <td>-0.557241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4371</th>\n",
       "      <td>2.847339</td>\n",
       "      <td>2.814420</td>\n",
       "      <td>2.813744</td>\n",
       "      <td>114.129997</td>\n",
       "      <td>-0.556193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4372</th>\n",
       "      <td>2.787502</td>\n",
       "      <td>2.805814</td>\n",
       "      <td>2.812731</td>\n",
       "      <td>114.500000</td>\n",
       "      <td>-0.746313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4373</th>\n",
       "      <td>2.823939</td>\n",
       "      <td>2.815082</td>\n",
       "      <td>2.860678</td>\n",
       "      <td>115.639999</td>\n",
       "      <td>-0.363545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4374</th>\n",
       "      <td>2.848676</td>\n",
       "      <td>2.809786</td>\n",
       "      <td>2.851562</td>\n",
       "      <td>114.830002</td>\n",
       "      <td>-0.607808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4375</th>\n",
       "      <td>2.829956</td>\n",
       "      <td>2.814751</td>\n",
       "      <td>2.862029</td>\n",
       "      <td>115.570000</td>\n",
       "      <td>-0.579935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4376</th>\n",
       "      <td>2.838982</td>\n",
       "      <td>2.810117</td>\n",
       "      <td>2.806653</td>\n",
       "      <td>113.570000</td>\n",
       "      <td>-0.556563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4377</th>\n",
       "      <td>2.768114</td>\n",
       "      <td>2.737958</td>\n",
       "      <td>2.772212</td>\n",
       "      <td>113.110001</td>\n",
       "      <td>-0.462150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4378</th>\n",
       "      <td>2.760760</td>\n",
       "      <td>2.783637</td>\n",
       "      <td>2.779303</td>\n",
       "      <td>114.220001</td>\n",
       "      <td>-0.490271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4379</th>\n",
       "      <td>2.790845</td>\n",
       "      <td>2.786947</td>\n",
       "      <td>2.821510</td>\n",
       "      <td>114.220001</td>\n",
       "      <td>-0.278012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>2.789174</td>\n",
       "      <td>2.750867</td>\n",
       "      <td>2.776602</td>\n",
       "      <td>112.709999</td>\n",
       "      <td>0.117151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>2.748057</td>\n",
       "      <td>2.732993</td>\n",
       "      <td>2.763095</td>\n",
       "      <td>112.750000</td>\n",
       "      <td>-0.379023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4382</th>\n",
       "      <td>2.754074</td>\n",
       "      <td>2.731007</td>\n",
       "      <td>2.751277</td>\n",
       "      <td>111.760002</td>\n",
       "      <td>-0.417873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4383</th>\n",
       "      <td>2.741037</td>\n",
       "      <td>2.732662</td>\n",
       "      <td>2.776602</td>\n",
       "      <td>113.110001</td>\n",
       "      <td>-0.514197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384</th>\n",
       "      <td>2.733014</td>\n",
       "      <td>2.726042</td>\n",
       "      <td>2.751952</td>\n",
       "      <td>111.830002</td>\n",
       "      <td>-0.319453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4385</th>\n",
       "      <td>2.722986</td>\n",
       "      <td>2.717436</td>\n",
       "      <td>2.744862</td>\n",
       "      <td>112.690002</td>\n",
       "      <td>-0.588815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4386</th>\n",
       "      <td>2.749728</td>\n",
       "      <td>2.743916</td>\n",
       "      <td>2.775589</td>\n",
       "      <td>113.660004</td>\n",
       "      <td>-0.488791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4387</th>\n",
       "      <td>2.782154</td>\n",
       "      <td>2.754177</td>\n",
       "      <td>2.787407</td>\n",
       "      <td>113.309998</td>\n",
       "      <td>-0.575988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4388</th>\n",
       "      <td>2.739700</td>\n",
       "      <td>2.735310</td>\n",
       "      <td>2.732368</td>\n",
       "      <td>111.870003</td>\n",
       "      <td>-0.048610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4389</th>\n",
       "      <td>2.723320</td>\n",
       "      <td>2.700885</td>\n",
       "      <td>2.701641</td>\n",
       "      <td>112.230003</td>\n",
       "      <td>0.155816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4390</th>\n",
       "      <td>2.737694</td>\n",
       "      <td>2.714457</td>\n",
       "      <td>2.760732</td>\n",
       "      <td>112.339996</td>\n",
       "      <td>-0.390000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4391</th>\n",
       "      <td>2.732346</td>\n",
       "      <td>2.777017</td>\n",
       "      <td>2.761069</td>\n",
       "      <td>113.190002</td>\n",
       "      <td>-0.167936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4392 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Open      High       Low       Close    Volume\n",
       "0    -0.894209 -0.885022 -0.892306    4.125000  1.104812\n",
       "1    -0.883762 -0.886056 -0.885975    4.015625 -0.497301\n",
       "2    -0.887941 -0.889159 -0.887558    4.000000 -0.892217\n",
       "3    -0.887941 -0.890194 -0.891251    3.843750 -0.000263\n",
       "4    -0.896820 -0.898986 -0.906551    3.390625  3.729366\n",
       "5    -0.904655 -0.900020 -0.904969    3.437500  5.921757\n",
       "6    -0.903610 -0.904158 -0.916576    3.500000  6.939265\n",
       "7    -0.905700 -0.904675 -0.904441    3.484375  2.753792\n",
       "8    -0.904655 -0.903641 -0.903913    3.578125  3.266616\n",
       "9    -0.901521 -0.896400 -0.899693    3.609375  7.412869\n",
       "10   -0.898387 -0.898469 -0.898637    3.640625  2.094693\n",
       "11   -0.902044 -0.901572 -0.900748    3.578125  2.902040\n",
       "12   -0.903088 -0.902089 -0.901803    3.578125  4.108496\n",
       "13   -0.902044 -0.901572 -0.900220    3.613275  3.077421\n",
       "14   -0.900999 -0.902606 -0.901803    3.609375  0.457554\n",
       "15   -0.902044 -0.903124 -0.902331    3.562500  0.683255\n",
       "16   -0.900999 -0.902606 -0.903386    3.515625  0.624055\n",
       "17   -0.902566 -0.901572 -0.900748    3.593750  1.713344\n",
       "18   -0.902044 -0.900538 -0.900748    3.656250  1.649456\n",
       "19   -0.901521 -0.901572 -0.901803    3.562500  1.190899\n",
       "20   -0.902044 -0.897434 -0.903913    3.765625  1.696817\n",
       "21   -0.895253 -0.886056 -0.894417    3.828125  2.119607\n",
       "22   -0.895776 -0.897952 -0.898110    3.703125  1.357401\n",
       "23   -0.898387 -0.898469 -0.898637    3.750000  1.020698\n",
       "24   -0.896298 -0.898469 -0.899165    3.687500  1.496028\n",
       "25   -0.899432 -0.900538 -0.899165    3.640625  0.493567\n",
       "26   -0.903088 -0.902089 -0.902331    3.562500  1.406241\n",
       "27   -0.901521 -0.900538 -0.900748    3.687500  1.064605\n",
       "28   -0.897343 -0.895366 -0.895472    3.781250 -0.106824\n",
       "29   -0.893164 -0.893297 -0.892834    3.812500 -0.276532\n",
       "...        ...       ...       ...         ...       ...\n",
       "4362  2.854359  2.823358  2.806653  115.510002  0.185663\n",
       "4363  2.848676  2.812765  2.830965  115.180000 -0.256614\n",
       "4364  2.851685  2.824351  2.865743  115.269997 -0.361880\n",
       "4365  2.831294  2.799856  2.790108  114.239998 -0.391295\n",
       "4366  2.797531  2.843549  2.820159  116.449997 -0.255565\n",
       "4367  2.883442  2.850169  2.878912  116.190002 -0.568095\n",
       "4368  2.862716  2.841563  2.891743  116.480003 -0.715849\n",
       "4369  2.872076  2.859768  2.889042  116.160004 -0.559400\n",
       "4370  2.847673  2.833619  2.869795  116.260002 -0.557241\n",
       "4371  2.847339  2.814420  2.813744  114.129997 -0.556193\n",
       "4372  2.787502  2.805814  2.812731  114.500000 -0.746313\n",
       "4373  2.823939  2.815082  2.860678  115.639999 -0.363545\n",
       "4374  2.848676  2.809786  2.851562  114.830002 -0.607808\n",
       "4375  2.829956  2.814751  2.862029  115.570000 -0.579935\n",
       "4376  2.838982  2.810117  2.806653  113.570000 -0.556563\n",
       "4377  2.768114  2.737958  2.772212  113.110001 -0.462150\n",
       "4378  2.760760  2.783637  2.779303  114.220001 -0.490271\n",
       "4379  2.790845  2.786947  2.821510  114.220001 -0.278012\n",
       "4380  2.789174  2.750867  2.776602  112.709999  0.117151\n",
       "4381  2.748057  2.732993  2.763095  112.750000 -0.379023\n",
       "4382  2.754074  2.731007  2.751277  111.760002 -0.417873\n",
       "4383  2.741037  2.732662  2.776602  113.110001 -0.514197\n",
       "4384  2.733014  2.726042  2.751952  111.830002 -0.319453\n",
       "4385  2.722986  2.717436  2.744862  112.690002 -0.588815\n",
       "4386  2.749728  2.743916  2.775589  113.660004 -0.488791\n",
       "4387  2.782154  2.754177  2.787407  113.309998 -0.575988\n",
       "4388  2.739700  2.735310  2.732368  111.870003 -0.048610\n",
       "4389  2.723320  2.700885  2.701641  112.230003  0.155816\n",
       "4390  2.737694  2.714457  2.760732  112.339996 -0.390000\n",
       "4391  2.732346  2.777017  2.761069  113.190002 -0.167936\n",
       "\n",
       "[4392 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_numeric_zscore(df, 'Open', mean=None, sd=None)\n",
    "encode_numeric_zscore(df, 'High', mean=None, sd=None)\n",
    "encode_numeric_zscore(df, 'Low', mean=None, sd=None)\n",
    "encode_numeric_zscore(df, 'Volume', mean=None, sd=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation - Relu and Optimizer - Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (3074, 4)\n",
      "x_test shape: (1318, 4)\n",
      "y_train shape: (3074,)\n",
      "y_train shape: (1318,)\n"
     ]
    }
   ],
   "source": [
    "x,y = to_xy(df,\"Close\")\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=42)\n",
    "print(\"x_train shape:\",x_train.shape)\n",
    "print(\"x_test shape:\",x_test.shape)\n",
    "print(\"y_train shape:\",y_train.shape)\n",
    "print(\"y_train shape:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/1000\n",
      "3074/3074 - 1s - loss: 1853.3326 - val_loss: 1757.4398\n",
      "Epoch 2/1000\n",
      "3074/3074 - 0s - loss: 1848.1066 - val_loss: 1751.0085\n",
      "Epoch 3/1000\n",
      "3074/3074 - 0s - loss: 1840.9818 - val_loss: 1742.6568\n",
      "Epoch 4/1000\n",
      "3074/3074 - 0s - loss: 1831.9415 - val_loss: 1731.8254\n",
      "Epoch 5/1000\n",
      "3074/3074 - 0s - loss: 1815.4685 - val_loss: 1700.1461\n",
      "Epoch 6/1000\n",
      "3074/3074 - 0s - loss: 1742.1235 - val_loss: 1599.8674\n",
      "Epoch 7/1000\n",
      "3074/3074 - 0s - loss: 1639.5384 - val_loss: 1498.7464\n",
      "Epoch 8/1000\n",
      "3074/3074 - 0s - loss: 1532.5636 - val_loss: 1392.5251\n",
      "Epoch 9/1000\n",
      "3074/3074 - 0s - loss: 1413.3529 - val_loss: 1278.2280\n",
      "Epoch 10/1000\n",
      "3074/3074 - 0s - loss: 1295.5206 - val_loss: 1157.9647\n",
      "Epoch 11/1000\n",
      "3074/3074 - 0s - loss: 1163.7703 - val_loss: 1028.6878\n",
      "Epoch 12/1000\n",
      "3074/3074 - 0s - loss: 1016.5148 - val_loss: 880.2326\n",
      "Epoch 13/1000\n",
      "3074/3074 - 0s - loss: 855.5264 - val_loss: 716.7006\n",
      "Epoch 14/1000\n",
      "3074/3074 - 0s - loss: 678.2869 - val_loss: 549.3034\n",
      "Epoch 15/1000\n",
      "3074/3074 - 0s - loss: 514.6419 - val_loss: 408.0810\n",
      "Epoch 16/1000\n",
      "3074/3074 - 0s - loss: 374.7754 - val_loss: 288.7763\n",
      "Epoch 17/1000\n",
      "3074/3074 - 0s - loss: 260.2979 - val_loss: 193.6295\n",
      "Epoch 18/1000\n",
      "3074/3074 - 0s - loss: 176.1987 - val_loss: 131.1359\n",
      "Epoch 19/1000\n",
      "3074/3074 - 0s - loss: 121.4881 - val_loss: 92.5725\n",
      "Epoch 20/1000\n",
      "3074/3074 - 0s - loss: 87.9899 - val_loss: 69.7571\n",
      "Epoch 21/1000\n",
      "3074/3074 - 0s - loss: 68.8336 - val_loss: 57.5916\n",
      "Epoch 22/1000\n",
      "3074/3074 - 0s - loss: 57.9605 - val_loss: 50.5364\n",
      "Epoch 23/1000\n",
      "3074/3074 - 0s - loss: 51.9232 - val_loss: 46.8586\n",
      "Epoch 24/1000\n",
      "3074/3074 - 0s - loss: 48.3899 - val_loss: 44.2470\n",
      "Epoch 25/1000\n",
      "3074/3074 - 0s - loss: 45.3957 - val_loss: 41.8518\n",
      "Epoch 26/1000\n",
      "3074/3074 - 0s - loss: 42.8514 - val_loss: 39.8010\n",
      "Epoch 27/1000\n",
      "3074/3074 - 0s - loss: 40.4292 - val_loss: 37.7103\n",
      "Epoch 28/1000\n",
      "3074/3074 - 0s - loss: 38.1552 - val_loss: 35.6898\n",
      "Epoch 29/1000\n",
      "3074/3074 - 0s - loss: 35.8671 - val_loss: 33.7755\n",
      "Epoch 30/1000\n",
      "3074/3074 - 0s - loss: 33.7010 - val_loss: 31.7770\n",
      "Epoch 31/1000\n",
      "3074/3074 - 0s - loss: 31.7132 - val_loss: 30.0846\n",
      "Epoch 32/1000\n",
      "3074/3074 - 0s - loss: 29.9502 - val_loss: 28.4474\n",
      "Epoch 33/1000\n",
      "3074/3074 - 0s - loss: 28.1971 - val_loss: 26.8560\n",
      "Epoch 34/1000\n",
      "3074/3074 - 0s - loss: 26.5889 - val_loss: 25.4181\n",
      "Epoch 35/1000\n",
      "3074/3074 - 0s - loss: 24.9718 - val_loss: 23.9825\n",
      "Epoch 36/1000\n",
      "3074/3074 - 0s - loss: 23.4736 - val_loss: 22.7052\n",
      "Epoch 37/1000\n",
      "3074/3074 - 0s - loss: 22.1891 - val_loss: 21.6061\n",
      "Epoch 38/1000\n",
      "3074/3074 - 0s - loss: 21.0515 - val_loss: 20.6080\n",
      "Epoch 39/1000\n",
      "3074/3074 - 0s - loss: 20.0232 - val_loss: 19.6694\n",
      "Epoch 40/1000\n",
      "3074/3074 - 0s - loss: 19.1321 - val_loss: 18.8373\n",
      "Epoch 41/1000\n",
      "3074/3074 - 0s - loss: 18.2972 - val_loss: 18.0791\n",
      "Epoch 42/1000\n",
      "3074/3074 - 0s - loss: 17.5017 - val_loss: 17.3088\n",
      "Epoch 43/1000\n",
      "3074/3074 - 0s - loss: 16.7058 - val_loss: 16.5436\n",
      "Epoch 44/1000\n",
      "3074/3074 - 0s - loss: 15.9622 - val_loss: 15.8330\n",
      "Epoch 45/1000\n",
      "3074/3074 - 0s - loss: 15.2429 - val_loss: 15.1406\n",
      "Epoch 46/1000\n",
      "3074/3074 - 0s - loss: 14.5431 - val_loss: 14.4099\n",
      "Epoch 47/1000\n",
      "3074/3074 - 0s - loss: 13.8253 - val_loss: 13.6502\n",
      "Epoch 48/1000\n",
      "3074/3074 - 0s - loss: 13.0844 - val_loss: 12.9328\n",
      "Epoch 49/1000\n",
      "3074/3074 - 0s - loss: 12.3144 - val_loss: 12.2744\n",
      "Epoch 50/1000\n",
      "3074/3074 - 0s - loss: 11.6513 - val_loss: 11.6516\n",
      "Epoch 51/1000\n",
      "3074/3074 - 0s - loss: 11.0075 - val_loss: 11.0517\n",
      "Epoch 52/1000\n",
      "3074/3074 - 0s - loss: 10.4047 - val_loss: 10.4710\n",
      "Epoch 53/1000\n",
      "3074/3074 - 0s - loss: 9.8317 - val_loss: 9.9209\n",
      "Epoch 54/1000\n",
      "3074/3074 - 0s - loss: 9.2854 - val_loss: 9.3270\n",
      "Epoch 55/1000\n",
      "3074/3074 - 0s - loss: 8.7576 - val_loss: 8.8228\n",
      "Epoch 56/1000\n",
      "3074/3074 - 0s - loss: 8.2828 - val_loss: 8.3689\n",
      "Epoch 57/1000\n",
      "3074/3074 - 0s - loss: 7.8048 - val_loss: 7.8817\n",
      "Epoch 58/1000\n",
      "3074/3074 - 0s - loss: 7.3461 - val_loss: 7.4170\n",
      "Epoch 59/1000\n",
      "3074/3074 - 0s - loss: 6.9078 - val_loss: 6.9789\n",
      "Epoch 60/1000\n",
      "3074/3074 - 0s - loss: 6.4854 - val_loss: 6.5272\n",
      "Epoch 61/1000\n",
      "3074/3074 - 0s - loss: 6.0472 - val_loss: 6.0896\n",
      "Epoch 62/1000\n",
      "3074/3074 - 0s - loss: 5.6488 - val_loss: 5.7188\n",
      "Epoch 63/1000\n",
      "3074/3074 - 0s - loss: 5.2709 - val_loss: 5.3093\n",
      "Epoch 64/1000\n",
      "3074/3074 - 0s - loss: 4.8707 - val_loss: 4.8982\n",
      "Epoch 65/1000\n",
      "3074/3074 - 0s - loss: 4.4071 - val_loss: 4.4122\n",
      "Epoch 66/1000\n",
      "3074/3074 - 0s - loss: 3.9636 - val_loss: 3.9675\n",
      "Epoch 67/1000\n",
      "3074/3074 - 0s - loss: 3.5556 - val_loss: 3.5961\n",
      "Epoch 68/1000\n",
      "3074/3074 - 0s - loss: 3.1948 - val_loss: 3.2640\n",
      "Epoch 69/1000\n",
      "3074/3074 - 0s - loss: 2.8967 - val_loss: 2.9925\n",
      "Epoch 70/1000\n",
      "3074/3074 - 0s - loss: 2.6412 - val_loss: 2.7584\n",
      "Epoch 71/1000\n",
      "3074/3074 - 0s - loss: 2.4175 - val_loss: 2.5515\n",
      "Epoch 72/1000\n",
      "3074/3074 - 0s - loss: 2.2130 - val_loss: 2.3499\n",
      "Epoch 73/1000\n",
      "3074/3074 - 0s - loss: 2.0283 - val_loss: 2.1857\n",
      "Epoch 74/1000\n",
      "3074/3074 - 0s - loss: 1.8707 - val_loss: 2.0349\n",
      "Epoch 75/1000\n",
      "3074/3074 - 0s - loss: 1.7251 - val_loss: 1.8883\n",
      "Epoch 76/1000\n",
      "3074/3074 - 0s - loss: 1.6012 - val_loss: 1.7714\n",
      "Epoch 77/1000\n",
      "3074/3074 - 0s - loss: 1.4939 - val_loss: 1.6713\n",
      "Epoch 78/1000\n",
      "3074/3074 - 0s - loss: 1.4045 - val_loss: 1.5877\n",
      "Epoch 79/1000\n",
      "3074/3074 - 0s - loss: 1.3275 - val_loss: 1.5108\n",
      "Epoch 80/1000\n",
      "3074/3074 - 0s - loss: 1.2646 - val_loss: 1.4361\n",
      "Epoch 81/1000\n",
      "3074/3074 - 0s - loss: 1.1939 - val_loss: 1.3723\n",
      "Epoch 82/1000\n",
      "3074/3074 - 0s - loss: 1.1331 - val_loss: 1.3115\n",
      "Epoch 83/1000\n",
      "3074/3074 - 0s - loss: 1.0816 - val_loss: 1.2565\n",
      "Epoch 84/1000\n",
      "3074/3074 - 0s - loss: 1.0335 - val_loss: 1.1995\n",
      "Epoch 85/1000\n",
      "3074/3074 - 0s - loss: 0.9948 - val_loss: 1.1460\n",
      "Epoch 86/1000\n",
      "3074/3074 - 0s - loss: 0.9493 - val_loss: 1.0982\n",
      "Epoch 87/1000\n",
      "3074/3074 - 0s - loss: 0.9084 - val_loss: 1.0482\n",
      "Epoch 88/1000\n",
      "3074/3074 - 0s - loss: 0.8712 - val_loss: 1.0038\n",
      "Epoch 89/1000\n",
      "3074/3074 - 0s - loss: 0.8316 - val_loss: 0.9614\n",
      "Epoch 90/1000\n",
      "3074/3074 - 0s - loss: 0.7993 - val_loss: 0.9213\n",
      "Epoch 91/1000\n",
      "3074/3074 - 0s - loss: 0.7623 - val_loss: 0.8844\n",
      "Epoch 92/1000\n",
      "3074/3074 - 0s - loss: 0.7303 - val_loss: 0.8454\n",
      "Epoch 93/1000\n",
      "3074/3074 - 0s - loss: 0.7014 - val_loss: 0.8117\n",
      "Epoch 94/1000\n",
      "3074/3074 - 0s - loss: 0.6734 - val_loss: 0.7785\n",
      "Epoch 95/1000\n",
      "3074/3074 - 0s - loss: 0.6494 - val_loss: 0.7471\n",
      "Epoch 96/1000\n",
      "3074/3074 - 0s - loss: 0.6245 - val_loss: 0.7176\n",
      "Epoch 97/1000\n",
      "3074/3074 - 0s - loss: 0.6014 - val_loss: 0.6901\n",
      "Epoch 98/1000\n",
      "3074/3074 - 0s - loss: 0.5843 - val_loss: 0.6637\n",
      "Epoch 99/1000\n",
      "3074/3074 - 0s - loss: 0.5659 - val_loss: 0.6368\n",
      "Epoch 100/1000\n",
      "3074/3074 - 0s - loss: 0.5389 - val_loss: 0.6117\n",
      "Epoch 101/1000\n",
      "3074/3074 - 0s - loss: 0.5198 - val_loss: 0.5900\n",
      "Epoch 102/1000\n",
      "3074/3074 - 0s - loss: 0.5025 - val_loss: 0.5668\n",
      "Epoch 103/1000\n",
      "3074/3074 - 0s - loss: 0.4846 - val_loss: 0.5454\n",
      "Epoch 104/1000\n",
      "3074/3074 - 0s - loss: 0.4677 - val_loss: 0.5265\n",
      "Epoch 105/1000\n",
      "3074/3074 - 0s - loss: 0.4535 - val_loss: 0.5073\n",
      "Epoch 106/1000\n",
      "3074/3074 - 0s - loss: 0.4378 - val_loss: 0.4895\n",
      "Epoch 107/1000\n",
      "3074/3074 - 0s - loss: 0.4240 - val_loss: 0.4729\n",
      "Epoch 108/1000\n",
      "3074/3074 - 0s - loss: 0.4105 - val_loss: 0.4551\n",
      "Epoch 109/1000\n",
      "3074/3074 - 0s - loss: 0.3980 - val_loss: 0.4414\n",
      "Epoch 110/1000\n",
      "3074/3074 - 0s - loss: 0.3874 - val_loss: 0.4269\n",
      "Epoch 111/1000\n",
      "3074/3074 - 0s - loss: 0.3752 - val_loss: 0.4133\n",
      "Epoch 112/1000\n",
      "3074/3074 - 0s - loss: 0.3658 - val_loss: 0.4001\n",
      "Epoch 113/1000\n",
      "3074/3074 - 0s - loss: 0.3542 - val_loss: 0.3880\n",
      "Epoch 114/1000\n",
      "3074/3074 - 0s - loss: 0.3464 - val_loss: 0.3767\n",
      "Epoch 115/1000\n",
      "3074/3074 - 0s - loss: 0.3393 - val_loss: 0.3672\n",
      "Epoch 116/1000\n",
      "3074/3074 - 0s - loss: 0.3301 - val_loss: 0.3588\n",
      "Epoch 117/1000\n",
      "3074/3074 - 0s - loss: 0.3219 - val_loss: 0.3465\n",
      "Epoch 118/1000\n",
      "3074/3074 - 0s - loss: 0.3147 - val_loss: 0.3380\n",
      "Epoch 119/1000\n",
      "3074/3074 - 0s - loss: 0.3084 - val_loss: 0.3304\n",
      "Epoch 120/1000\n",
      "3074/3074 - 0s - loss: 0.3021 - val_loss: 0.3228\n",
      "Epoch 121/1000\n",
      "3074/3074 - 0s - loss: 0.2974 - val_loss: 0.3159\n",
      "Epoch 122/1000\n",
      "3074/3074 - 0s - loss: 0.2908 - val_loss: 0.3084\n",
      "Epoch 123/1000\n",
      "3074/3074 - 0s - loss: 0.2882 - val_loss: 0.3019\n",
      "Epoch 124/1000\n",
      "3074/3074 - 0s - loss: 0.2809 - val_loss: 0.2960\n",
      "Epoch 125/1000\n",
      "3074/3074 - 0s - loss: 0.2754 - val_loss: 0.2897\n",
      "Epoch 126/1000\n",
      "3074/3074 - 0s - loss: 0.2713 - val_loss: 0.2843\n",
      "Epoch 127/1000\n",
      "3074/3074 - 0s - loss: 0.2672 - val_loss: 0.2785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/1000\n",
      "3074/3074 - 0s - loss: 0.2671 - val_loss: 0.2747\n",
      "Epoch 129/1000\n",
      "3074/3074 - 0s - loss: 0.2647 - val_loss: 0.2693\n",
      "Epoch 130/1000\n",
      "3074/3074 - 0s - loss: 0.2566 - val_loss: 0.2646\n",
      "Epoch 131/1000\n",
      "3074/3074 - 0s - loss: 0.2533 - val_loss: 0.2611\n",
      "Epoch 132/1000\n",
      "3074/3074 - 0s - loss: 0.2535 - val_loss: 0.2568\n",
      "Epoch 133/1000\n",
      "3074/3074 - 0s - loss: 0.2476 - val_loss: 0.2527\n",
      "Epoch 134/1000\n",
      "3074/3074 - 0s - loss: 0.2451 - val_loss: 0.2490\n",
      "Epoch 135/1000\n",
      "3074/3074 - 0s - loss: 0.2412 - val_loss: 0.2456\n",
      "Epoch 136/1000\n",
      "3074/3074 - 0s - loss: 0.2387 - val_loss: 0.2414\n",
      "Epoch 137/1000\n",
      "3074/3074 - 0s - loss: 0.2363 - val_loss: 0.2380\n",
      "Epoch 138/1000\n",
      "3074/3074 - 0s - loss: 0.2349 - val_loss: 0.2347\n",
      "Epoch 139/1000\n",
      "3074/3074 - 0s - loss: 0.2341 - val_loss: 0.2312\n",
      "Epoch 140/1000\n",
      "3074/3074 - 0s - loss: 0.2297 - val_loss: 0.2284\n",
      "Epoch 141/1000\n",
      "3074/3074 - 0s - loss: 0.2278 - val_loss: 0.2260\n",
      "Epoch 142/1000\n",
      "3074/3074 - 0s - loss: 0.2269 - val_loss: 0.2240\n",
      "Epoch 143/1000\n",
      "3074/3074 - 0s - loss: 0.2269 - val_loss: 0.2215\n",
      "Epoch 144/1000\n",
      "3074/3074 - 0s - loss: 0.2227 - val_loss: 0.2190\n",
      "Epoch 145/1000\n",
      "3074/3074 - 0s - loss: 0.2202 - val_loss: 0.2168\n",
      "Epoch 146/1000\n",
      "3074/3074 - 0s - loss: 0.2193 - val_loss: 0.2144\n",
      "Epoch 147/1000\n",
      "3074/3074 - 0s - loss: 0.2171 - val_loss: 0.2126\n",
      "Epoch 148/1000\n",
      "3074/3074 - 0s - loss: 0.2151 - val_loss: 0.2120\n",
      "Epoch 149/1000\n",
      "3074/3074 - 0s - loss: 0.2448 - val_loss: 0.2286\n",
      "Epoch 150/1000\n",
      "3074/3074 - 0s - loss: 0.2265 - val_loss: 0.2092\n",
      "Epoch 151/1000\n",
      "3074/3074 - 0s - loss: 0.2130 - val_loss: 0.2085\n",
      "Epoch 152/1000\n",
      "3074/3074 - 0s - loss: 0.2181 - val_loss: 0.2059\n",
      "Epoch 153/1000\n",
      "3074/3074 - 0s - loss: 0.2133 - val_loss: 0.2039\n",
      "Epoch 154/1000\n",
      "3074/3074 - 0s - loss: 0.2086 - val_loss: 0.2016\n",
      "Epoch 155/1000\n",
      "3074/3074 - 0s - loss: 0.2068 - val_loss: 0.1999\n",
      "Epoch 156/1000\n",
      "3074/3074 - 0s - loss: 0.2053 - val_loss: 0.1983\n",
      "Epoch 157/1000\n",
      "3074/3074 - 0s - loss: 0.2059 - val_loss: 0.1968\n",
      "Epoch 158/1000\n",
      "3074/3074 - 0s - loss: 0.2033 - val_loss: 0.1958\n",
      "Epoch 159/1000\n",
      "3074/3074 - 0s - loss: 0.2027 - val_loss: 0.1944\n",
      "Epoch 160/1000\n",
      "3074/3074 - 0s - loss: 0.2021 - val_loss: 0.1929\n",
      "Epoch 161/1000\n",
      "3074/3074 - 0s - loss: 0.2013 - val_loss: 0.1919\n",
      "Epoch 162/1000\n",
      "3074/3074 - 0s - loss: 0.2026 - val_loss: 0.1928\n",
      "Epoch 163/1000\n",
      "3074/3074 - 0s - loss: 0.2013 - val_loss: 0.1915\n",
      "Epoch 164/1000\n",
      "3074/3074 - 0s - loss: 0.2017 - val_loss: 0.1887\n",
      "Epoch 165/1000\n",
      "3074/3074 - 0s - loss: 0.1989 - val_loss: 0.1876\n",
      "Epoch 166/1000\n",
      "3074/3074 - 0s - loss: 0.2051 - val_loss: 0.1892\n",
      "Epoch 167/1000\n",
      "3074/3074 - 0s - loss: 0.1983 - val_loss: 0.1858\n",
      "Epoch 168/1000\n",
      "3074/3074 - 0s - loss: 0.1960 - val_loss: 0.1848\n",
      "Epoch 169/1000\n",
      "3074/3074 - 0s - loss: 0.1959 - val_loss: 0.1841\n",
      "Epoch 170/1000\n",
      "3074/3074 - 0s - loss: 0.1951 - val_loss: 0.1830\n",
      "Epoch 171/1000\n",
      "3074/3074 - 0s - loss: 0.1949 - val_loss: 0.1828\n",
      "Epoch 172/1000\n",
      "3074/3074 - 0s - loss: 0.1989 - val_loss: 0.1833\n",
      "Epoch 173/1000\n",
      "3074/3074 - 0s - loss: 0.1951 - val_loss: 0.1814\n",
      "Epoch 174/1000\n",
      "3074/3074 - 0s - loss: 0.1946 - val_loss: 0.1819\n",
      "Epoch 175/1000\n",
      "3074/3074 - 0s - loss: 0.1926 - val_loss: 0.1813\n",
      "Epoch 176/1000\n",
      "3074/3074 - 0s - loss: 0.1938 - val_loss: 0.1793\n",
      "Epoch 177/1000\n",
      "3074/3074 - 0s - loss: 0.1925 - val_loss: 0.1781\n",
      "Epoch 178/1000\n",
      "3074/3074 - 0s - loss: 0.1927 - val_loss: 0.1773\n",
      "Epoch 179/1000\n",
      "3074/3074 - 0s - loss: 0.1904 - val_loss: 0.1771\n",
      "Epoch 180/1000\n",
      "3074/3074 - 0s - loss: 0.1909 - val_loss: 0.1769\n",
      "Epoch 181/1000\n",
      "3074/3074 - 0s - loss: 0.1905 - val_loss: 0.1765\n",
      "Epoch 182/1000\n",
      "3074/3074 - 0s - loss: 0.1902 - val_loss: 0.1757\n",
      "Epoch 183/1000\n",
      "3074/3074 - 0s - loss: 0.1917 - val_loss: 0.1760\n",
      "Epoch 184/1000\n",
      "3074/3074 - 0s - loss: 0.1892 - val_loss: 0.1753\n",
      "Epoch 185/1000\n",
      "3074/3074 - 0s - loss: 0.1927 - val_loss: 0.1749\n",
      "Epoch 186/1000\n",
      "3074/3074 - 0s - loss: 0.1894 - val_loss: 0.1747\n",
      "Epoch 187/1000\n",
      "3074/3074 - 0s - loss: 0.1890 - val_loss: 0.1740\n",
      "Epoch 188/1000\n",
      "3074/3074 - 0s - loss: 0.1909 - val_loss: 0.1738\n",
      "Epoch 189/1000\n",
      "3074/3074 - 0s - loss: 0.1899 - val_loss: 0.1749\n",
      "Epoch 190/1000\n",
      "3074/3074 - 0s - loss: 0.1882 - val_loss: 0.1730\n",
      "Epoch 191/1000\n",
      "3074/3074 - 0s - loss: 0.1881 - val_loss: 0.1730\n",
      "Epoch 192/1000\n",
      "3074/3074 - 0s - loss: 0.1879 - val_loss: 0.1726\n",
      "Epoch 193/1000\n",
      "3074/3074 - 0s - loss: 0.1877 - val_loss: 0.1722\n",
      "Epoch 194/1000\n",
      "3074/3074 - 0s - loss: 0.1887 - val_loss: 0.1733\n",
      "Epoch 195/1000\n",
      "3074/3074 - 0s - loss: 0.1880 - val_loss: 0.1727\n",
      "Epoch 196/1000\n",
      "3074/3074 - 0s - loss: 0.1871 - val_loss: 0.1714\n",
      "Epoch 197/1000\n",
      "3074/3074 - 0s - loss: 0.1889 - val_loss: 0.1715\n",
      "Epoch 198/1000\n",
      "3074/3074 - 0s - loss: 0.1880 - val_loss: 0.1715\n",
      "Epoch 199/1000\n",
      "3074/3074 - 0s - loss: 0.1865 - val_loss: 0.1705\n",
      "Epoch 200/1000\n",
      "3074/3074 - 0s - loss: 0.1857 - val_loss: 0.1715\n",
      "Epoch 201/1000\n",
      "3074/3074 - 0s - loss: 0.1883 - val_loss: 0.1709\n",
      "Epoch 00201: early stopping\n",
      "Score (RMSE): 0.4134465456008911\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(10, input_dim=x.shape[1], activation='relu'))\n",
    "model.add(Dense(5,activation='relu'))\n",
    "model.add(Dense(1,activation='relu'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=2, mode='auto')  \n",
    "\n",
    "# patience: number of epochs with no improvement after which training will be stopped\n",
    "\n",
    "# The test set is checked during training to monitor progress for early stopping but is never used for gradient descent (model training)\n",
    "\n",
    "model.fit(x_train, y_train, validation_data=(x_test,y_test), batch_size=128, callbacks=[monitor], verbose=2, epochs=1000) \n",
    "\n",
    "pred= model.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Score (RMSE): {}\".format(score))\n",
    "chart_regression(pred.flatten(),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation - Relu and Optimizer - SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/1000\n",
      "3074/3074 - 1s - loss: 389.4300 - val_loss: 314.4379\n",
      "Epoch 2/1000\n",
      "3074/3074 - 0s - loss: 191.5835 - val_loss: 449.9016\n",
      "Epoch 3/1000\n",
      "3074/3074 - 0s - loss: 166.8056 - val_loss: 1381.3255\n",
      "Epoch 4/1000\n",
      "3074/3074 - 0s - loss: 452.9890 - val_loss: 9.3468\n",
      "Epoch 5/1000\n",
      "3074/3074 - 0s - loss: 100.3973 - val_loss: 21.0677\n",
      "Epoch 6/1000\n",
      "3074/3074 - 0s - loss: 113.2029 - val_loss: 386.9268\n",
      "Epoch 7/1000\n",
      "3074/3074 - 0s - loss: 141.1747 - val_loss: 673.3226\n",
      "Epoch 8/1000\n",
      "3074/3074 - 0s - loss: 111.2368 - val_loss: 3.1262\n",
      "Epoch 9/1000\n",
      "3074/3074 - 0s - loss: 101.0864 - val_loss: 6.0770\n",
      "Epoch 10/1000\n",
      "3074/3074 - 0s - loss: 32.9130 - val_loss: 2.2467\n",
      "Epoch 11/1000\n",
      "3074/3074 - 0s - loss: 87.7395 - val_loss: 1.4630\n",
      "Epoch 12/1000\n",
      "3074/3074 - 0s - loss: 42.0814 - val_loss: 471.8939\n",
      "Epoch 13/1000\n",
      "3074/3074 - 0s - loss: 120.5621 - val_loss: 210.8353\n",
      "Epoch 14/1000\n",
      "3074/3074 - 0s - loss: 48.6747 - val_loss: 1764.8990\n",
      "Epoch 15/1000\n",
      "3074/3074 - 0s - loss: 1214.3661 - val_loss: 957.9320\n",
      "Epoch 16/1000\n",
      "3074/3074 - 0s - loss: 434.0207 - val_loss: 5.8820\n",
      "Epoch 00016: early stopping\n",
      "Score (RMSE): 2.425281047821045\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(5, input_dim=x.shape[1], activation='relu'))\n",
    "model.add(Dense(1,activation='relu'))\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=2, mode='auto')  \n",
    "\n",
    "# patience: number of epochs with no improvement after which training will be stopped\n",
    "\n",
    "# The test set is checked during training to monitor progress for early stopping but is never used for gradient descent (model training)\n",
    "\n",
    "model.fit(x_train, y_train, validation_data=(x_test,y_test), batch_size=128, callbacks=[monitor], verbose=2, epochs=1000) \n",
    "\n",
    "pred= model.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Score (RMSE): {}\".format(score))\n",
    "chart_regression(pred.flatten(),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
